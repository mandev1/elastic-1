input {
  syslog {
    host => "{IP Address}"
    port => 5514
    type => "aruba-cx"
  }
  syslog {
    host => "{IP Address}"
    port => 5516
    type => "sangfor-hci"
  }
  syslog {
    host => "{IP Address}"
    port => 5518
    type => "sangfor-vdi"
  }
  syslog {
    host => "{IP Address}"
    port => 5520
    type => "tor-switch"
  }
}

filter {
  if [type] == "aruba-cx" {

    # --- Syslog Header Parsing ---
    grok {
      match => {
        "message" => "<%{INT:syslog_pri}>1 %{TIMESTAMP_ISO8601:syslog_timestamp} %{HOSTNAME:hostname} %{WORD:appname} (?:%{INT:process_id}|-) - - %{GREEDYDATA:msg}"
      }
      tag_on_failure => ["_grok_syslog_fail"]
    }

    date {
      match   => ["syslog_timestamp", "ISO8601"]
      target  => "@timestamp"
      # timezone dihapus agar tidak double offset
    }
    mutate { add_field => { "event_timestamp" => "%{syslog_timestamp}" } }

    # --- Aruba Event Logs ---
    if [msg] =~ /^Event\|/ {
      grok {
        match => {
          "msg" => [
            "Event\|%{INT:event_id}\|%{DATA:log_level}\|\|\|%{GREEDYDATA:event_message}",
            "Event\|%{INT:event_id}\|%{DATA:log_level}\|%{DATA:module}\|%{DATA:slot}\|%{GREEDYDATA:event_message}"
          ]
        }
        tag_on_failure => ["_grok_event_fail"]
      }
      mutate { convert => { "event_id" => "string" } }

      translate {
        field           => "event_id"
        destination     => "event_description"
        dictionary_path => "/etc/logstash/conf.d/aruba_event_description.yml"
        fallback        => "Unknown event ID"
        exact           => true
      }

      translate {
        field           => "event_id"
        destination     => "event_severity"
        dictionary_path => "/etc/logstash/conf.d/aruba_event_severity.yml"
        fallback        => "%{log_level}"
        exact           => true
      }
    }

    # --- Aruba CLI Audit ---
    if [msg] =~ /^AUDIT\|CLI/ {
      grok {
        match => {
          "msg" => "AUDIT\|CLI \"%{DATA:cli_command}\" executed by user '%{DATA:user}' from address '%{IP:source_ip}' through %{DATA:access_method} session which resulted in %{WORD:result} at timezone %{DATA:timezone}\."
        }
        tag_on_failure => ["_grok_cli_fail"]
      }
      mutate { rename => { "msg" => "event_message" } }
    }

    # --- Sudo Logs ---
    if [appname] == "sudo" and [msg] =~ /COMMAND=/ {
      grok {
        match => {
          "msg" => "%{USER:user} : TTY=%{DATA:tty} ; PWD=%{DATA:pwd} ; USER=%{USER:runas_user} ; COMMAND=%{GREEDYDATA:sudo_command}"
        }
        tag_on_failure => ["_grok_sudo_fail"]
      }
      mutate { rename => { "msg" => "event_message" } }
    }

    # --- Nginx SSL Errors ---
    if [appname] == "nginx" {
      grok {
        match => {
          "msg" => "%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME:nginx_timestamp} \[%{LOGLEVEL:log_level}\] %{INT:pid}#%{INT:tid}: \*%{INT:conn_id} SSL_do_handshake\(\) failed \(SSL: %{GREEDYDATA:ssl_error}\) while SSL handshaking, client: %{IPV6:client_ip}, server: \[::\]:%{INT:server_port}"
        }
        tag_on_failure => ["_grok_nginx_fail"]
      }
      mutate {
        rename  => { "msg" => "event_message" }
        replace => { "event_timestamp" => "%{nginx_timestamp}" }
      }
      date {
        match    => ["nginx_timestamp", "yyyy/MM/dd HH:mm:ss"]
        target   => "@timestamp"
        timezone => "Asia/Jakarta"   # tetap pakai timezone, karena log ini biasanya tanpa offset
      }
    }

    # --- Systemd PAM Logs ---
    if [appname] == "systemd" {
      grok {
        match => {
          "msg" => "pam_warn\(%{DATA:service}\): function=\[%{DATA:function}\] flags=%{DATA:flags} service=\[%{DATA:pam_service}\] terminal=\[%{DATA:terminal}\] user=\[%{DATA:user}\] ruser=\[%{DATA:ruser}\] rhost=\[%{DATA:rhost}\]"
        }
        tag_on_failure => ["_grok_systemd_fail"]
      }
      mutate { rename => { "msg" => "event_message" } }
    }

    # --- Systemd Logind ---
    if [appname] == "systemd-logind" {
      grok {
        match => {
          "msg" => [
            "New session %{DATA:session_id} of user %{WORD:user}\.",
            "Removed session %{DATA:session_id}\."
          ]
        }
        tag_on_failure => ["_grok_logind_fail"]
      }
      mutate { add_field => { "event_message" => "%{msg}" } }
    }

    # --- Aruba Log-Proxyd ---
    if [appname] == "log-proxyd" {
      grok {
        match => {
          "msg" => "Event\|%{INT:event_id}\|%{DATA:log_level}\|%{WORD:module}\|%{DATA:session}\|%{GREEDYDATA:event_message}"
        }
        tag_on_failure => ["_grok_logproxyd_fail"]
      }
    }

    # --- Aruba hpe-restd ---
    if [appname] == "hpe-restd" {
      grok {
        match => {
          "msg" => [
            "Event\|%{INT:event_id}\|%{DATA:log_level}\|%{DATA:module}\|%{DATA:session}\|Certificate %{DATA:certificate} verified and accepted",
            "Event\|%{INT:event_id}\|%{DATA:log_level}\|%{DATA:module}\|%{DATA:session}\|Certificate %{DATA:certificate} is cryptographically validated by CA certificate %{GREEDYDATA:ca_issuer}"
          ]
        }
        tag_on_failure => ["_grok_hperestd_fail"]
      }
      mutate { convert => { "event_id" => "string" } }

      translate {
        field           => "event_id"
        destination     => "event_description"
        dictionary_path => "/etc/logstash/conf.d/aruba_event_description.yml"
        fallback        => "Unknown event ID"
        exact           => true
      }

      translate {
        field           => "event_id"
        destination     => "event_severity"
        dictionary_path => "/etc/logstash/conf.d/aruba_event_severity.yml"
        fallback        => "%{log_level}"
        exact           => true
      }
    }

    # --- Aruba hpe-pvstd ---
    if [appname] == "hpe-pvstd" {
      grok {
        match => {
          "msg" => "Event\|%{INT:event_id}\|%{DATA:log_level}\|%{WORD:module}\|%{DATA:session}\|Topology change received on port %{WORD:interface} from source: %{MAC:src_mac} on VLAN %{INT:vlan}"
        }
        tag_on_failure => ["_grok_pvstd_fail"]
      }
      mutate { convert => { "event_id" => "string" } }

      translate {
        field           => "event_id"
        destination     => "event_description"
        dictionary_path => "/etc/logstash/conf.d/aruba_event_description.yml"
        fallback        => "Unknown event ID"
        exact           => true
      }

      translate {
        field           => "event_id"
        destination     => "event_severity"
        dictionary_path => "/etc/logstash/conf.d/aruba_event_severity.yml"
        fallback        => "%{log_level}"
        exact           => true
      }
    }

    # --- SSHD Logs ---
    if [appname] == "sshd" {
      grok {
        match => {
          "msg" => [
            "Disconnected from %{IP:src_ip} port %{INT:src_port} \[%{DATA:auth_stage}\]",
            "Received disconnect from %{IP:src_ip} port %{INT:src_port}: reason %{INT:reason_code}: *%{GREEDYDATA:reason_msg} \[%{DATA:auth_stage}\]"
          ]
        }
        tag_on_failure => ["_grok_sshd_fail"]
      }
      mutate { rename => { "msg" => "event_message" } }
    }

    # --- Fallback if msg exists but no event_message ---
    if [msg] and ![event_message] {
      mutate { add_field => { "event_message" => "%{msg}" } }
    }

    # --- General Fallback for Unknown Patterns ---
    if [msg] and [msg] !~ /^Event\|/ and [appname] not in ["sudo","nginx","systemd","systemd-logind","log-proxyd","hpe-restd","hpe-pvstd","sshd"] {
      grok {
        match => {
          "msg" => "%{TIMESTAMP_ISO8601:fallback_time} \[%{LOGLEVEL:log_level}\] %{DATA:error_detail} %{GREEDYDATA:event_message}"
        }
        tag_on_failure => ["_grok_msg_fail"]
      }
      date {
        match    => ["fallback_time", "ISO8601"]
        target   => "@timestamp"
        # timezone dihapus karena fallback_time kemungkinan sudah ISO8601 dengan offset
      }
      mutate { replace => { "event_timestamp" => "%{fallback_time}" } }
    }

    # --- Add Metadata ---
    mutate {
      add_field => {
        "device_vendor" => "Aruba"
        "device_type"   => "Switch"
      }
    }
  }

    else if [type] == "sangfor-hci" {
        # --- Syslog Header Parsing (RFC3164) ---
        grok {
            match => {
                "event.original" => "<%{INT:syslog_pri}>%{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTNAME:host.hostname} %{DATA:process.name}(?:\\[%{POSINT:process.pid}\\])?: %{GREEDYDATA:message}"
            }
            tag_on_failure => ["_grok_sangfor_syslog_fail"]
        }

        # --- Kernel Plain Message ---
        if [process.name] == "kernel" and [message] =~ /^\[[0-9]+\.[0-9]+\]/ {
            grok {
                match => {
                    "message" => "\\[%{NUMBER:kernel_uptime:float}\\] %{DATA:driver} %{DATA:pci_addr}: %{GREEDYDATA:event_message}"
                }
                tag_on_failure => ["_grok_sangfor_kernel_fail"]
            }
        }

        # --- Exporter JSON Message ---
        else if [process.name] == "exporter" and [message] =~ /^\{.*\}$/ {
            json {
                source => "message"
                target => "exporter_json"
                tag_on_failure => ["_json_exporter_fail"]
            }
            mutate {
                rename => { "[exporter_json][content]" => "event_message" }
                rename => { "[exporter_json][trace]"   => "trace_id" }
                remove_field => ["exporter_json"]
            }
        }

        # --- Scheduler JSON Message ---
        else if [process.name] == "scheduler" and [message] =~ /^\{.*\}$/ {
            json {
                source => "message"
                target => "scheduler_json"
                tag_on_failure => ["_json_scheduler_fail"]
            }
            mutate {
                rename => { "[scheduler_json][content]" => "event_message" }
                rename => { "[scheduler_json][trace]"   => "trace_id" }
                remove_field => ["scheduler_json"]
            }
        }

        # --- Simpan timestamp syslog sebagai @timestamp ---
        if [syslog_timestamp] {
            date {
                match => [
                    "syslog_timestamp",
                    "MMM  d HH:mm:ss",
                    "MMM dd HH:mm:ss",
                    "YYYY-MM-dd HH:mm:ss"
                ]
                timezone => "Asia/Jakarta"
                target => "@timestamp"
                tag_on_failure => ["_timestamp_fail"]
            }
        }

        mutate {
            add_field => {
                "device_vendor" => "Sangfor"
                "device_type"   => "HCI"
            }
        }
    }
}


output {
  if [type] == "aruba-cx" {
    elasticsearch {
      hosts    => ["https://{IP Address}:9200"]
      index    => "core_switch-logs-%{+YYYY.MM.dd}"
      user     => "{username}"
      password => "{password}"
      ssl      => true
      ssl_certificate_verification => false
    }
    file {
      path  => "/var/log/logstash/Core-Switch/Core-%{+YYYY-MM-dd}.log"
      codec => json_lines
    }
  }

  else if [type] == "sangfor-hci" {
    elasticsearch {
      hosts    => ["https://{IP Address}:9200"]
      index    => "sangfor_hci-logs-%{+YYYY.MM.dd}"
      user     => "{username}"
      password => "{password}"
      ssl      => true
      ssl_certificate_verification => false
    }
    file {
      path  => "/var/log/logstash/Sangfor/HCI/Sangfor_HCI-%{+YYYY-MM-dd}.log"
      codec => json_lines
    }

  }

  else if [type] == "sangfor-vdi" {
    elasticsearch {
      hosts    => ["https://{IP Address}:9200"]
      index    => "sangfor_vdi-logs-%{+YYYY.MM.dd}"
      user     => "{username}"
      password => "{password}"
      ssl      => true
      ssl_certificate_verification => false
    }
    file {
      path  => "/var/log/logstash/Sangfor/VDI/Sangfor_VDI-%{+YYYY-MM-dd}.log"
      codec => json_lines
    }

  }

  else if [type] == "tor-switch" {
    elasticsearch {
      hosts    => ["https://{IP Address}:9200"]
      index    => "tor_switch-logs-%{+YYYY.MM.dd}"
      user     => "{username}"
      password => "{password}"
      ssl      => true
      ssl_certificate_verification => false
    }
    file {
      path  => "/var/log/logstash/Tor-Switch/Tor_Switch-%{+YYYY-MM-dd}.log"
      codec => json_lines
    }

      }
    
  }



}
